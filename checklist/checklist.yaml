%YAML 1.2
---
Title: Checklist for Tests in Machine Learning Projects
# TODO: To be filled in later...
Description: Description about the project and its context
Test Areas:
  - Topic: General
    Description: >
      The following items describe best practices for all tests to be
      written.
    Tests:
      - Title: Write Descriptive Test Names
        Requirement: >
          Every test function should have a clear, descriptive name
        Explanation: >
          If out tests are narrow and sufficiently descriptive, the test
          name itself may give us enough information to start debugging.
          This also helps us to identify what is being tested inside the
          function.
        References:
          - https://testing.googleblog.com/2014/10/testing-on-toilet-writing-descriptive.html
          - https://testing.googleblog.com/2024/05/test-failures-should-be-actionable.html

      - Title: Keep Tests Focused
        Requirement: >
          Each test should only test one scenario, meaning that in each
          test we should only use one set of mock data.
        Explanation: >
          If we test multiple scenarios in a single test, it is hard to
          idenitfy exactly what went wrong. Keeping one scenario in a
          single test helps us to isolate problematic scenarios.
        References:
          - https://testing.googleblog.com/2018/06/testing-on-toilet-keep-tests-focused.html

      - Title: Prefer Narrow Assertions in Unit Tests
        Requirement: >
          The assertions inside the tests should be narrow, meaning that
          when checking a complex object, any unrelated behavior should
          not be tested - Assert on only relevant behaviors.
        Explanation: >
          If we have overly wide assertions (such as depending on every
          field of a complex output proto), the test may fail for many
          unimportant reasons. False positives are the opoosite of
          actionable.
        References:
          - https://testing.googleblog.com/2024/04/prefer-narrow-assertions-in-unit-tests.html

      - Title: Keep Cause and Effect Clear
        Requirement: >
          The modifications and the assertions of an object's behavior
          in a single test should not be far away from each other.
        Explanation: >
          Refrain from using large global test data structures shared
          across multiple unit tests. This will allow for clear
          identification of each test's setup and the cause and effect.
        References:
          - https://testing.googleblog.com/2017/01/testing-on-toilet-keep-cause-and-effect.html

  - Topic: Data Presence
    Description: >
      The following items describe tests that need to be done for testing
      the presence of data.
    Tests:
      - Title: Validate Data File Loading Functionality
        Requirement: >
          Verify that the function for loading data files operates correctly across various file formats and handles errors gracefully.
        Explanation: >
          This item ensures that the data loading mechanism is robust, correctly parses different file types, and provides useful error messages when unable to load data. This test is crucial for the initial steps of data handling in the pipeline.
        References:
          - https://microsoft.github.io/code-with-engineering-playbook
          - UBC-MDS

      - Title: Validate Data and Figures Saving Functionality
        Requirement: >
          Ensure that the function for saving data and figures operates correctly, saving files in the specified formats and locations without corruption or data loss.
        Explanation: >
          This item tests the reliability and effectiveness of the saving mechanism used in the project. It is crucial for preserving the results of data analyses and visualizations for future use or review.
        References:
          - https://microsoft.github.io/code-with-engineering-playbook
          - UBC-MDS

  - Topic: Data Quality
    Description: >
      The following items describe tests that need to be done for testing
      the quality of data.
    Tests:
      - Title: Verify File Content
        Requirement: >
          Ensure that all data files are non-empty and contain the necessary data to proceed with the analysis or processing tasks.
        Explanation: >
          This checklist item is crucial as it confirms the presence of usable data within the files. It prevents errors in later stages of the project by ensuring data is available from the start.
        References:
          - https://microsoft.github.io/code-with-engineering-playbook 
          - UBC-MDS
      
      - Title: Verify Data/Image Format
        Requirement: >
          Check that all data and images are in the formats expected by the processing algorithms (e.g., CSV, JPEG, PNG) and that their structure matches the expected schema.
        Explanation: >
          Ensuring that data and images are in the correct format is essential for compatibility with processing tools and algorithms, which may not handle unexpected formats gracefully.
        References:
          - https://microsoft.github.io/code-with-engineering-playbook 
          - UBC-MDS 

      - Title: Check for Nulls and Outliers
        Requirement: >
          Verify that the data files are free of null values and identify any outliers that may skew the results or affect the analysis.
        Explanation: >
          Null values can lead to errors or inaccurate computations in many data processing applications, while outliers can distort statistical analyses and models.
        References:
          - https://microsoft.github.io/code-with-engineering-playbook 
          - UBC-MDS

  - Topic: Data Ingestion
    Description: >
      This section of the checklist ensures that all data cleaning and transformation processes are functioning as intended and produce the expected outputs.
    Tests:
      - Title: Validate Data Cleaning and Transformation
        Requirement: >
          Confirm that data cleaning and transformation functions execute without errors and result in data that meets predefined standards and formats.
        Explanation: >
          Proper functioning of data cleaning and transformation routines is crucial as they prepare the raw data for analysis, removing inconsistencies, and standardizing formats which are essential for downstream processes.
        References:
          - https://microsoft.github.io/code-with-engineering-playbook 
          - UBC-MDS 


  - Topic: Model Fitting
    Description: >
      The following items describe tests that need to be done for testing
      the model fitting process.
    Tests:
      - Title: Validate Model Input and Output Compatibility
        Requirement: >
          Confirm that the model accepts the correct input shapes and types, and produces outputs of the expected shapes and types without errors.
        Explanation: >
          Ensuring that inputs and outputs conform to expected specifications is critical for the correct functioning of the model in a production environment.
        References:
          - http://microsoft.github.io/code-with-engineering-playbook
          - UBC-MDS

      - Title: Verify Model Weight Updates
        Requirement: >
          Check that during training, the model's weights are being updated correctly as expected per training iteration.
        Explanation: >
          Weight updates are fundamental to the learning process, indicating that the model is learning from the training data.
        References:
          - http://microsoft.github.io/code-with-engineering-playbook

      - Title: Assess Model Output Alignment with Expectations
        Requirement: >
          Ensure that the outputs of the model align with what is expected based on the inputs, especially in classification tasks where the output labels should match expected categories.
        Explanation: >
          Correct output alignment confirms that the model is accurately interpreting the input data and making predictions that are sensible given the context.
        References:
          - https://www.jeremyjordan.me/testing-ml/

      - Title: Check Output Probability Distribution
        Requirement: >
          Verify that the outputs, especially in probabilistic outputs like in classification models, sum to 1 and align with probability distribution expectations.
        Explanation: >
          This ensures that the model's output is valid in probabilistic terms and usable for decision-making in classification contexts.
        References:
          - https://www.jeremyjordan.me/testing-ml/

      - Title: Validate Loss Reduction on Gradient Update
        Requirement: >
          Test if a single gradient update step during training effectively reduces the model's loss, indicating proper backpropagation.
        Explanation: >
          A decrease in loss after a gradient update demonstrates that the model is improving and learning from the data.
        References:
          - https://www.jeremyjordan.me/testing-ml/

      - Title: Check for Data Leakage
        Requirement: >
          Confirm that there is no leakage between training, validation, and test datasets, which can result in misleadingly high performance metrics.
        Explanation: >
          Data leakage can compromise the model's ability to generalize to unseen data, making it crucial to ensure datasets are properly segregated.
        References:
          - https://www.jeremyjordan.me/testing-ml/


  - Topic: Model Evaluation
    Description: >
      The following items describe tests that need to be done for testing
      the model evaluation process.
    Tests:
      - Title: Dummy Title
        Requirement: >
          This is a dummy item and there is nothing needed to act on.
        Explanation: >
          This is a dummy item to show how the checklist items would be
          stored inside this YAML file. It serves no other propose.
        References:
          - http://128.0.0.1
          - UBC-MDS

  - Topic: Artifact Testing
    Description: >
      The following items describe tests that need to be done for testing
      any artifacts that are created from the project.
    Tests:
      - Title: Dummy Title
        Requirement: >
          This is a dummy item and there is nothing needed to act on.
        Explanation: >
          This is a dummy item to show how the checklist items would be
          stored inside this YAML file. It serves no other propose.
        References:
          - http://128.0.0.1
          - UBC-MDS
