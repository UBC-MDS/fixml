{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c1ead7-9d5b-4414-80e2-07092ba180ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import DirectoryLoader, PythonLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Prepare .env and API Key before running the script below\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb7fff1-47b5-4e3d-b204-07eb523b32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312da605-da7d-4493-8acc-11301e5ef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc\n",
    "# loader = DirectoryLoader(\n",
    "#     # '../../../lightfm/tests', \n",
    "#     '../../../SVD_Compression/llm_test/test', \n",
    "#     glob=\"**/*.py\", \n",
    "#     show_progress=True, \n",
    "#     #use_multithreading=True,\n",
    "#     loader_cls=PythonLoader\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# # vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "# # retriever = vectorstore.as_retriever()\n",
    "# # context = retriever.invoke(\"How many test functions are there?\")\n",
    "\n",
    "# # define prompt and chat\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"Analyze the test functions from the codes below:\\n\\n{context}\"),\n",
    "#     MessagesPlaceholder(variable_name=\"messages\")\n",
    "# ])\n",
    "\n",
    "# # chat = ChatOpenAI(model='gpt-4-turbo')\n",
    "# chat = ChatOpenAI(model='gpt-4o', temperature=0.1)\n",
    "\n",
    "# # combine prompt, chat and doc\n",
    "# docs_chain = create_stuff_documents_chain(chat, prompt) \n",
    "\n",
    "# for chunk in docs_chain.stream({\n",
    "#     \"context\": all_splits,\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(content=\"How many test functions are there? Can you list them all?\")\n",
    "#     ],\n",
    "# }):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93c3bb-de00-4ede-b2a5-a8c85f0d9d44",
   "metadata": {},
   "source": [
    "### Sample Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad8f2fc-5d20-48bb-a989-0c6d028196e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_sample = '''\n",
    "1. Does it contain test case to ensure models are loaded correctly without errors, checking for issues in model setup or initialization?\n",
    "2. Does it contain test case to verify that the output dimensions and values from model predictions match expected outcomes?\n",
    "3. Does it contain test case to confirm the accuracy and correctness of evaluation metrics used within the system, ensuring that metrics such as precision, recall, AUC, etc., are computed correctly?\n",
    "4. Does it contain test case to evaluate the model’s performance over training to identify potential overfitting? This could involve comparing training and validation loss.\n",
    "5. Does it contain test case to define and enforce performance thresholds for crucial metrics to guarantee model performance?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d6d3a4-8dab-4431-88a7-97ab9b150f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 2027.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# load doc\n",
    "loader = DirectoryLoader(\n",
    "    #'../../../lightfm/tests', \n",
    "    '../../data/raw/openja/lightfm/tests',\n",
    "    # '../../../SVD_Compression/llm_test/test', \n",
    "    glob=\"**/*.py\", \n",
    "    show_progress=True, \n",
    "    #use_multithreading=True,\n",
    "    loader_cls=PythonLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o', \n",
    "                  temperature=0.1,\n",
    "                 )\n",
    "\n",
    "# define prompt and chat\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a senior machine learning engineer who specializes in performing Machine Learning system testing. Extract and analyze the test functions from the codes:\\n\\n{context}\"),\n",
    "    (\"system\", f\"Here is the Machine Learning system testing checklist delimited by triple quotes '''{checklist_sample}'''\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "# combine prompt, chat and doc\n",
    "docs_chain = create_stuff_documents_chain(chat, prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20cfe1d4-3ffa-45b0-af26-cd85e36a1f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe6c7d8-d86c-4bfd-a29a-2cb3ae6b7a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checklist Evaluation:\n",
      "1. Requirement Title: Model Initialization\n",
      "   Requirement: Does it contain test case to ensure models are loaded correctly without errors, checking for issues in model setup or initialization?\n",
      "   Observation: The code includes multiple test cases that initialize models with various parameters and configurations, ensuring that models are loaded correctly without errors.\n",
      "   Evaluation: Fulfilled\n",
      "\n",
      "2. Requirement Title: Output Dimensions and Values\n",
      "   Requirement: Does it contain test case to verify that the output dimensions and values from model predictions match expected outcomes?\n",
      "   Observation: The code includes test cases such as `test_predict`, `test_predict_ranks`, and `test_get_representations` that verify the output dimensions and values from model predictions.\n",
      "   Evaluation: Fulfilled\n",
      "\n",
      "3. Requirement Title: Evaluation Metrics Accuracy\n",
      "   Requirement: Does it contain test case to confirm the accuracy and correctness of evaluation metrics used within the system, ensuring that metrics such as precision, recall, AUC, etc., are computed correctly?\n",
      "   Observation: The code includes test cases like `test_precision_at_k`, `test_recall_at_k`, `test_auc_score`, and `_get_metrics` that confirm the accuracy and correctness of evaluation metrics.\n",
      "   Evaluation: Fulfilled\n",
      "\n",
      "4. Requirement Title: Model Performance Over Training\n",
      "   Requirement: Does it contain test case to evaluate the model’s performance over training to identify potential overfitting? This could involve comparing training and validation loss.\n",
      "   Observation: The code includes test cases such as `test_overfitting`, `test_regularization`, and `test_movielens_accuracy_resume` that evaluate the model’s performance over training to identify potential overfitting.\n",
      "   Evaluation: Fulfilled\n",
      "\n",
      "5. Requirement Title: Performance Thresholds\n",
      "   Requirement: Does it contain test case to define and enforce performance thresholds for crucial metrics to guarantee model performance?\n",
      "   Observation: The code includes assertions in test cases like `test_movielens_accuracy`, `test_logistic_precision`, `test_bpr_precision`, and others to enforce performance thresholds for crucial metrics.\n",
      "   Evaluation: Fulfilled\n",
      "\n",
      "Completion Score: 5/5"
     ]
    }
   ],
   "source": [
    "for chunk in docs_chain.stream({\n",
    "    \"context\": docs,\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"\"\"\n",
    "        Evaluate whether the codes has fulfilled the requirements and deliver a completion score. Do not include a summary evaluation.\n",
    "        Desired format:\n",
    "        Checklist Evaluation:\n",
    "            Requirement Title:\n",
    "            Requirement:\n",
    "            Observation:\n",
    "            Evaluation:\n",
    "        Completion Score:\n",
    "        \"\"\")\n",
    "    ],\n",
    "}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ef33f-3a78-47e5-ba80-d79243ba4d8e",
   "metadata": {},
   "source": [
    "### Real Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38312472-2a3e-483b-a410-99aed41650e0",
   "metadata": {},
   "source": [
    "#### Checklist - Before Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1a9f2a-bb75-4e34-8d70-da09d793f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_project = '''\n",
    "'Every test function should have a clear, descriptive name',\n",
    "'Each test should only test one scenario, meaning that in each test we should only use one set of mock data.',\n",
    "'The assertions inside the tests should be narrow, meaning that when checking a complex object, any unrelated behavior should not be tested - Assert on only relevant behaviors.',\n",
    "\"The modifications and the assertions of an object's behavior in a single test should not be far away from each other.\",\n",
    "\"Verify the function for loading data files load the file if the files exists with the right format, and doesn't load the file if it doesn't exist, and that it returns the expected results.\",\n",
    "'Verify the functions for saving data and figures can write as expected. They should check the if the write operation is successfully carried out, and the content is in an expected format.',\n",
    "'Ensure that all data files are non-empty and contain the necessary data to proceed with the analysis or processing tasks.',\n",
    "'Check that the data to be ingested is in the format expected by the processing algorithms (e.g., Is the CSV loaded as a `pd.DataFrame`? Is the image file loaded as a `np.array`, or a `PIL.Image`?) and that their structure matches the expected schema, any present.',\n",
    "'Verify that the data files are free of unexpected null values and identify any outliers that may skew the results or affect the analysis. If null values are expected, it must be explicitly stated in the tests.',\n",
    "'Test input and output so that a fixed input would get an expected output. One such test could be testing the output shap of the data after transformation. Ideally, each test should be limited to test just one verification.',\n",
    "'Confirm that the model accepts the correct input shapes and types, and produces outputs of the expected shapes and types without errors.',\n",
    "\"If a parametric model is used during the training process, make sure that the model's weights are being updated correctly as expected per training iteration. If a non-parametric model is used, check if the data is fitted into the model.\",\n",
    "'Ensure that the shape of model output aligns with what is expected based the task of the model. For example, in classification task, the shape of the model output should be aligned with the number of labels in the dataset.',\n",
    "'Verify that the output values are aligned with the task of the model. For example, a classification model would output probabilities which should sum to 1.',\n",
    "\"If the model relies on gradient descent for training, make sure a single gradient step on a batch of data yields a decrease in the model's training loss.\",\n",
    "'Confirm that there is no leakage between train/val/test or CV splits.',\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8538d-ef96-4e3f-8b90-b3263d197fcb",
   "metadata": {},
   "source": [
    "#### Checklist - After Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ea485b-6fcc-4e72-b590-e9ddede81ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_project = \"\"\"\n",
    "Each test function should have a clear, descriptive name that accurately reflects the test's purpose and the specific functionality or scenario it examines.\n",
    "Each test should focus on a single scenario, using only one set of mock data and testing one specific behavior or outcome to ensure clarity and isolate issues.\n",
    "Assertions within tests should be focused and narrow. Ensure you are only testing relevant behaviors of complex objects and not including unrelated assertions.\n",
    "Keep any modifications to objects and the corresponding assertions close together in your tests to maintain readability and clearly show the cause-and-effect relationship.\n",
    "Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
    "Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\n",
    "Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\n",
    "Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\n",
    "Check that data files are free from unexpected null values and identify any outliers that could affect the analysis. Tests should explicitly state if null values are part of expected data.\n",
    "Test that a fixed input to a function or model produces the expected output, focusing on one verification per test to ensure predictable behavior.\n",
    "Confirm that the model accepts inputs of the correct shapes and types and produces outputs that meet the expected shapes and types without any errors.\n",
    "For parametric models, ensure that the model's weights update correctly per training iteration. For non-parametric models, verify that the data fits correctly into the model.\n",
    "Ensure the shape of the model's output aligns with the expected structure based on the task, such as matching the number of labels in a classification task.\n",
    "Verify that the model's output values are appropriate for its task, such as outputting probabilities that sum to 1 for classification tasks.\n",
    "If using gradient descent for training, verify that a single gradient step on a batch of data results in a decrease in the model's training loss.\n",
    "Confirm that there is no leakage of data between training, validation, and testing sets, or across cross-validation folds, to ensure the integrity of the splits.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08ea5f5-67b4-4380-874e-362289c14855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 1980.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# load doc\n",
    "loader = DirectoryLoader(\n",
    "    '../../../lightfm/tests', \n",
    "    # '../../../SVD_Compression/llm_test/test', \n",
    "    glob=\"**/*.py\", \n",
    "    show_progress=True, \n",
    "    #use_multithreading=True,\n",
    "    loader_cls=PythonLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o', \n",
    "                  temperature=0.1,\n",
    "                 )\n",
    "\n",
    "# define prompt and chat\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a senior machine learning engineer who specializes in performing Machine Learning system testing. Extract and analyze the test functions from the codes:\\n\\n{context}\"),\n",
    "    (\"system\", f\"Here is the Machine Learning system testing checklist delimited by triple quotes '''{checklist_project}'''\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "# combine prompt, chat and doc\n",
    "docs_chain = create_stuff_documents_chain(chat, prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0bb4b0c-d61a-46a9-8574-f8ed106c5c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checklist Evaluation:\n",
      "\n",
      "1. Requirement Title: Descriptive Test Function Names\n",
      "   Requirement: Each test function should have a clear, descriptive name that accurately reflects the test's purpose and the specific functionality or scenario it examines.\n",
      "   Observation: Test functions like `test_in_positives`, `test_movielens_accuracy`, `test_logistic_precision`, `test_bpr_precision`, etc., have clear and descriptive names.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "2. Requirement Title: Single Scenario Focus\n",
      "   Requirement: Each test should focus on a single scenario, using only one set of mock data and testing one specific behavior or outcome to ensure clarity and isolate issues.\n",
      "   Observation: Each test function focuses on a specific scenario, such as `test_movielens_accuracy` focusing on the accuracy of the Movielens dataset.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "3. Requirement Title: Focused Assertions\n",
      "   Requirement: Assertions within tests should be focused and narrow. Ensure you are only testing relevant behaviors of complex objects and not including unrelated assertions.\n",
      "   Observation: Assertions are focused on specific outcomes, e.g., `assert roc_auc_score(train.data, train_predictions) > 0.84` in `test_movielens_accuracy`.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "4. Requirement Title: Cause-and-Effect Clarity\n",
      "   Requirement: Keep any modifications to objects and the corresponding assertions close together in your tests to maintain readability and clearly show the cause-and-effect relationship.\n",
      "   Observation: Modifications and assertions are kept close together, e.g., in `test_movielens_accuracy`, the model is trained and then predictions are asserted.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "5. Requirement Title: Data-Loading Functions\n",
      "   Requirement: Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
      "   Observation: Data-loading functions are tested in `test_basic_fetching_movielens` and `test_basic_fetching_stackexchange`.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "6. Requirement Title: Data and Figures Saving Functions\n",
      "   Requirement: Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\n",
      "   Observation: No specific tests for saving data and figures are provided.\n",
      "   Evaluation: Not Satisfied\n",
      "\n",
      "7. Requirement Title: Non-Empty Data Files\n",
      "   Requirement: Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\n",
      "   Observation: No specific tests for checking non-empty data files are provided.\n",
      "   Evaluation: Not Satisfied\n",
      "\n",
      "8. Requirement Title: Data Format and Schema\n",
      "   Requirement: Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\n",
      "   Observation: Data format is implicitly checked in functions like `test_basic_fetching_movielens`.\n",
      "   Evaluation: Partially Satisfied\n",
      "\n",
      "9. Requirement Title: Null Values and Outliers\n",
      "   Requirement: Check that data files are free from unexpected null values and identify any outliers that could affect the analysis. Tests should explicitly state if null values are part of expected data.\n",
      "   Observation: No specific tests for null values and outliers are provided.\n",
      "   Evaluation: Not Satisfied\n",
      "\n",
      "10. Requirement Title: Fixed Input Produces Expected Output\n",
      "    Requirement: Test that a fixed input to a function or model produces the expected output, focusing on one verification per test to ensure predictable behavior.\n",
      "    Observation: Tests like `test_movielens_accuracy` check for expected outputs given fixed inputs.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "11. Requirement Title: Correct Input Shapes and Types\n",
      "    Requirement: Confirm that the model accepts inputs of the correct shapes and types and produces outputs that meet the expected shapes and types without any errors.\n",
      "    Observation: Tests like `test_input_dtypes` and `test_matrix_types` confirm correct input shapes and types.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "12. Requirement Title: Model Weights Update Correctly\n",
      "    Requirement: For parametric models, ensure that the model's weights update correctly per training iteration. For non-parametric models, verify that the data fits correctly into the model.\n",
      "    Observation: Tests like `test_training_schedules` check for correct weight updates.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "13. Requirement Title: Output Shape Alignment\n",
      "    Requirement: Ensure the shape of the model's output aligns with the expected structure based on the task, such as matching the number of labels in a classification task.\n",
      "    Observation: Tests like `test_predict` and `test_predict_ranks` check for correct output shapes.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "14. Requirement Title: Appropriate Output Values\n",
      "    Requirement: Verify that the model's output values are appropriate for its task, such as outputting probabilities that sum to 1 for classification tasks.\n",
      "    Observation: Tests like `test_movielens_accuracy` check for appropriate output values.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "15. Requirement Title: Gradient Descent Step\n",
      "    Requirement: If using gradient descent for training, verify that a single gradient step on a batch of data results in a decrease in the model's training loss.\n",
      "    Observation: Tests like `test_training_schedules` implicitly check for gradient descent steps.\n",
      "    Evaluation: Partially Satisfied\n",
      "\n",
      "16. Requirement Title: Data Leakage Prevention\n",
      "    Requirement: Confirm that there is no leakage of data between training, validation, and testing sets, or across cross-validation folds, to ensure the integrity of the splits.\n",
      "    Observation: Tests like `test_random_train_test_split` check for data leakage.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "Completion Score: 12/16\n",
      "    Number of satisfied requirements: 12\n",
      "    Number of partially satisfied requirements: 2\n",
      "    Number of not satisfied requirements: 2"
     ]
    }
   ],
   "source": [
    "for chunk in docs_chain.stream({\n",
    "    \"context\": docs,\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"\"\"\n",
    "        Your task is to answer each question in the checklist using only the provided test functions.\n",
    "        If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\n",
    "        Then, decide the completion score in a fraction format based on your answers. The denominator should be the number of checklist items.\n",
    "        Desired format:\n",
    "            Checklist Evaluation:\n",
    "                Requirement Title:\n",
    "                Requirement:\n",
    "                Observation:\n",
    "                Evaluation: Satisfied/Partially Satisfied/Not Satisfied\n",
    "            Completion Score: Number of satisfied requirements/Number of requirements\n",
    "                Number of satisfied requirements:\n",
    "                Number of partially satisfied requirements:\n",
    "                Number of not satisfied requirements:\n",
    "        \"\"\")\n",
    "    ],\n",
    "}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6210dbf0-096f-4e0e-b043-4d8ea87f75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checklist Evaluation:\n",
      "\n",
      "1. Requirement Title: Clear, Descriptive Test Names\n",
      "   Requirement: Each test function should have a clear, descriptive name that accurately reflects the test's purpose and the specific functionality or scenario it examines.\n",
      "   Observation: Test functions like `test_in_positives`, `test_movielens_accuracy`, `test_logistic_precision`, `test_bpr_precision`, etc., have clear and descriptive names.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "2. Requirement Title: Single Scenario Focus\n",
      "   Requirement: Each test should focus on a single scenario, using only one set of mock data and testing one specific behavior or outcome to ensure clarity and isolate issues.\n",
      "   Observation: Tests like `test_in_positives`, `test_movielens_accuracy`, and `test_logistic_precision` focus on specific scenarios and behaviors.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "3. Requirement Title: Focused Assertions\n",
      "   Requirement: Assertions within tests should be focused and narrow. Ensure you are only testing relevant behaviors of complex objects and not including unrelated assertions.\n",
      "   Observation: Assertions in tests like `test_in_positives` and `test_movielens_accuracy` are focused on specific behaviors.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "4. Requirement Title: Close Modifications and Assertions\n",
      "   Requirement: Keep any modifications to objects and the corresponding assertions close together in your tests to maintain readability and clearly show the cause-and-effect relationship.\n",
      "   Observation: Tests like `test_in_positives` and `test_movielens_accuracy` keep modifications and assertions close together.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "5. Requirement Title: Data-Loading Functions\n",
      "   Requirement: Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
      "   Observation: Tests like `test_basic_fetching_movielens` and `test_basic_fetching_stackexchange` ensure data-loading functions work correctly.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "6. Requirement Title: Saving Data and Figures\n",
      "   Requirement: Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\n",
      "   Observation: No specific tests for saving data and figures were found.\n",
      "   Evaluation: Not Satisfied\n",
      "\n",
      "7. Requirement Title: Non-Empty Data Files\n",
      "   Requirement: Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\n",
      "   Observation: Tests like `test_basic_fetching_movielens` and `test_basic_fetching_stackexchange` ensure data files are non-empty.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "8. Requirement Title: Data Format for Processing Algorithms\n",
      "   Requirement: Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\n",
      "   Observation: Tests like `test_basic_fetching_movielens` and `test_basic_fetching_stackexchange` ensure data format matches expectations.\n",
      "   Evaluation: Satisfied\n",
      "\n",
      "9. Requirement Title: Null Values and Outliers\n",
      "   Requirement: Check that data files are free from unexpected null values and identify any outliers that could affect the analysis. Tests should explicitly state if null values are part of expected data.\n",
      "   Observation: No specific tests for null values and outliers were found.\n",
      "   Evaluation: Not Satisfied\n",
      "\n",
      "10. Requirement Title: Fixed Input Produces Expected Output\n",
      "    Requirement: Test that a fixed input to a function or model produces the expected output, focusing on one verification per test to ensure predictable behavior.\n",
      "    Observation: Tests like `test_in_positives` and `test_movielens_accuracy` ensure fixed inputs produce expected outputs.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "11. Requirement Title: Correct Input Shapes and Types\n",
      "    Requirement: Confirm that the model accepts inputs of the correct shapes and types and produces outputs that meet the expected shapes and types without any errors.\n",
      "    Observation: Tests like `test_matrix_types` and `test_input_dtypes` ensure correct input shapes and types.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "12. Requirement Title: Model Weights Update Correctly\n",
      "    Requirement: For parametric models, ensure that the model's weights update correctly per training iteration. For non-parametric models, verify that the data fits correctly into the model.\n",
      "    Observation: Tests like `test_logistic_precision` and `test_bpr_precision` ensure model weights update correctly.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "13. Requirement Title: Output Shape Alignment\n",
      "    Requirement: Ensure the shape of the model's output aligns with the expected structure based on the task, such as matching the number of labels in a classification task.\n",
      "    Observation: Tests like `test_movielens_accuracy` and `test_logistic_precision` ensure output shape alignment.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "14. Requirement Title: Appropriate Output Values\n",
      "    Requirement: Verify that the model's output values are appropriate for its task, such as outputting probabilities that sum to 1 for classification tasks.\n",
      "    Observation: Tests like `test_movielens_accuracy` and `test_logistic_precision` ensure appropriate output values.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "15. Requirement Title: Gradient Descent Step\n",
      "    Requirement: If using gradient descent for training, verify that a single gradient step on a batch of data results in a decrease in the model's training loss.\n",
      "    Observation: Tests like `test_logistic_precision` and `test_bpr_precision` ensure gradient descent steps decrease training loss.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "16. Requirement Title: Data Leakage Prevention\n",
      "    Requirement: Confirm that there is no leakage of data between training, validation, and testing sets, or across cross-validation folds, to ensure the integrity of the splits.\n",
      "    Observation: Tests like `test_random_train_test_split` ensure no data leakage.\n",
      "    Evaluation: Satisfied\n",
      "\n",
      "Completion Score: 14/16\n",
      "    Number of satisfied requirements: 14\n",
      "    Number of partially satisfied requirements: 0\n",
      "    Number of not satisfied requirements: 2"
     ]
    }
   ],
   "source": [
    "for chunk in docs_chain.stream({\n",
    "    \"context\": all_splits,\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"\"\"\n",
    "        Your task is to answer each question in the checklist using only the provided test functions.\n",
    "        If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\n",
    "        Then, decide the completion score in a fraction format based on your answers. The denominator should be the number of checklist items.\n",
    "        Desired format:\n",
    "            Checklist Evaluation:\n",
    "                Requirement Title:\n",
    "                Requirement:\n",
    "                Observation:\n",
    "                Evaluation: Satisfied/Partially Satisfied/Not Satisfied\n",
    "            Completion Score: Number of satisfied requirements/Number of requirements\n",
    "                Number of satisfied requirements:\n",
    "                Number of partially satisfied requirements:\n",
    "                Number of not satisfied requirements:\n",
    "        \"\"\")\n",
    "    ],\n",
    "}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0e418-229b-4018-974b-e1dbe4615d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26664c2-44ef-4f03-99f0-b0cce674c4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ae2d9-9baf-487c-95c8-4ba51c36f119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test-creation]",
   "language": "python",
   "name": "conda-env-test-creation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
