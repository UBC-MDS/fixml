{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4933df8d-6a7e-45c8-8b05-d33811ee09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb2cc86-28c7-4080-a288-4bbdbb675bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "checklist = Checklist('../../checklist/checklist.csv', checklist_format=ChecklistFormat.CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ec0b9e-e7f9-4aa7-b28f-49054c6da0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestGenerator(llm, checklist=checklist)\n",
    "# generator.prompt = PromptTemplate(\n",
    "#     template=\"You are an expert Machine Learning Engineer.\\n\"\n",
    "#              \"Please generate empty test functions with numpy-format docstring based corresponding requirement of given checklist.\\n\"\n",
    "#              #\"{format_instructions}\\n\" # FIXME: define python function format\n",
    "#              \"Here is the checklist as a list of JSON objects:\\n```{checklist}```\\n\",\n",
    "#     description=\"Test Specification Generation for Machine Learning Project\",\n",
    "#     input_variables=[\"checklist\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9571619f-ffe2-45a4-a3fb-fc2d85e254f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_data_file_loads_as_expected():\n",
      "    \"\"\"\n",
      "    Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
      "    \"\"\"\n",
      "    pass\n"
     ]
    }
   ],
   "source": [
    "result = generator.generate_spec()\n",
    "print(result[0]['Function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec8fd8e-dcde-48d0-be58-d7f64f29637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '2.1', 'Title': 'Ensure Data File Loads as Expected', 'Function': ''},\n",
       " {'ID': '3.2', 'Title': 'Data in the Expected Format', 'Function': ''},\n",
       " {'ID': '3.5', 'Title': 'Check for Duplicate Records in Data', 'Function': ''},\n",
       " {'ID': '4.2', 'Title': 'Verify Data Split Proportion', 'Function': ''},\n",
       " {'ID': '5.3',\n",
       "  'Title': 'Ensure Model Output Shape Aligns with Expectation',\n",
       "  'Function': ''},\n",
       " {'ID': '6.1',\n",
       "  'Title': 'Verify Evaluation Metrics Implementation',\n",
       "  'Function': ''},\n",
       " {'ID': '6.2',\n",
       "  'Title': \"Evaluate Model's Performance Against Thresholds\",\n",
       "  'Function': ''}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1101f18-bb84-4f22-abac-0cb2b507db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generator.chain.invoke({\"checklist\": generator.test_items})\n",
    "\n",
    "result = response['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e4cc20-428c-4643-ad51-63f5604c7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_data_file_loads_as_expected():\n",
      "    \"\"\"\n",
      "    Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
      "    \"\"\"\n",
      "    pass\n"
     ]
    }
   ],
   "source": [
    "print(result[0]['Function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b523f4a-5187-45b1-96fe-b8bcc196e011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2b917-4d3f-40a0-a40d-1d6a34cebd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test-creation]",
   "language": "python",
   "name": "conda-env-test-creation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
