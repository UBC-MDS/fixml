{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b9be5c-c6c2-4fce-9bca-815f8772443a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78741377-167e-41d6-9542-c3593c0079ff",
   "metadata": {},
   "source": [
    "This Jupyter notebook is a tool to evaluate the consistency of ML Test Evaluation performed by ChatGPT based on the research paper (Alexander, R., Katz, L., Moore, C., & Schwartz, Z. (2023)). \\\n",
    "It serves the purpose of evaluating the application performance before and after checklist modification, and evaluating the application performance upon model setting changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427397a-321d-4ba8-ba63-512e18eea528",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12b6521a-4c59-4c34-ae5f-720706d2f1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import DirectoryLoader, PythonLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare .env and API Key before running the script below\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4a70a-f520-4a9e-83b0-92df5a10e82a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c1246-cb79-443c-a833-1784f4e25da3",
   "metadata": {},
   "source": [
    "Please specify the `test_functions_directory` below to load the ML test code base for the evaluation.\\\n",
    "The loaded test functions will be further split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "74036e8d-1dee-459b-bdf7-fa797b262e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_functions_directory = '../../../lightfm/tests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f26d3efb-8a3c-44e8-bccf-69acfb2e9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1078.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# load doc\n",
    "loader = DirectoryLoader(\n",
    "    path = test_functions_directory, \n",
    "    glob=\"**/*.py\", \n",
    "    show_progress=True, \n",
    "    #use_multithreading=True,\n",
    "    loader_cls=PythonLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828448c6-8bd4-448d-8964-cda9e3481f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2139ca-98d3-4253-a2e1-3ecdce1a1018",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03e63c-fb18-4361-b117-aa2355b7f5bb",
   "metadata": {},
   "source": [
    "Please specify the parameters, e.g. checklist, to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "210373f1-9354-434c-9103-5c4b767b14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperatures = [0, 0.2, 0.5, 1]\n",
    "temperatures = [0.1]\n",
    "models = ['gpt-3.5-turbo']\n",
    "roles = ['a senior machine learning engineer who specializes in performing Machine Learning system testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "457946ba-0723-45a1-9491-c40ede92992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_real_before = '''\n",
    "2.1: Verify the function for loading data files load the file if the files exists with the right format, and doesn't load the file if it doesn't exist, and that it returns the expected results.\n",
    "2.2: Verify the functions for saving data and figures can write as expected. They should check the if the write operation is successfully carried out, and the content is in an expected format.\n",
    "3.1: Ensure that all data files are non-empty and contain the necessary data to proceed with the analysis or processing tasks.\n",
    "3.2: Check that the data to be ingested is in the format expected by the processing algorithms (e.g., Is the CSV loaded as a `pd.DataFrame`? Is the image file loaded as a `np.array`, or a `PIL.Image`?) and that their structure matches the expected schema, any present.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "79a34d68-21a8-4667-a836-6d7f9d9c23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_real_after = \"\"\"\n",
    "2.1: Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
    "2.2: Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\n",
    "3.1: Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\n",
    "3.2: Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "46898c0d-dd18-4812-a6ba-fced01aabcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklists = [checklist_real_before] # , checklist_real_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "abc5a229-892d-47de-b882-cdb9b5ae154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = \"\"\"\n",
    "Your task is to answer each question in the checklist using only the provided test functions. Do not disclose your work for this step.\n",
    "Then, decide the completion score in a fraction format based on your answers.\n",
    "Desired JSON format:\n",
    "{\n",
    "    \"Checklist Evaluation\":\n",
    "        \"ID\": \n",
    "        \"Requirement\": -||-\n",
    "        \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\n",
    "    \"Completeness Score\": \n",
    "        \"Number of satisfied requirements\":\n",
    "        \"Number of partially satisfied requirements\":\n",
    "        \"Number of not satisfied requirements\":\n",
    "        \"Number of requirements\":\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7fa645b9-5293-4632-8278-b597c714eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompts = [human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7eccb8ce-962f-47f9-9693-d30a32dff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'Param_Set_ID': i,\n",
    "        'temperature': item[0],\n",
    "        'model': item[1],\n",
    "        'role': item[2],\n",
    "        'checklist': item[3],\n",
    "        'user_prompt': item[4],\n",
    "    } for i, item in enumerate(itertools.product(\n",
    "        temperatures, \n",
    "        models,\n",
    "        roles,\n",
    "        checklists,\n",
    "        user_prompts,\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fccbbab1-65de-495e-8071-38021e67cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th>temperature</th>\n",
       "      <th>model</th>\n",
       "      <th>role</th>\n",
       "      <th>checklist</th>\n",
       "      <th>user_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>a senior machine learning engineer who special...</td>\n",
       "      <td>\\n2.1: Verify the function for loading data fi...</td>\n",
       "      <td>\\nYour task is to answer each question in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Param_Set_ID  temperature          model  \\\n",
       "0             0          0.1  gpt-3.5-turbo   \n",
       "\n",
       "                                                role  \\\n",
       "0  a senior machine learning engineer who special...   \n",
       "\n",
       "                                           checklist  \\\n",
       "0  \\n2.1: Verify the function for loading data fi...   \n",
       "\n",
       "                                         user_prompt  \n",
       "0  \\nYour task is to answer each question in the ...  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cdd4a-6afe-4b39-8a65-46261ebaab16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9dee5f-fe3a-42ec-9daf-28ca7830d388",
   "metadata": {},
   "source": [
    "## API Running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ba74b-6ac9-4d6b-a11a-71f17a21614f",
   "metadata": {},
   "source": [
    "Incorporate the data, prompts and parameters, feed into OpenAI API for test runs and fetch responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ffbc27df-db63-4e57-ab9d-3d6121327d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bacf4e29-eb96-4fac-b340-1c9dbe328477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(response, start='{', end='}'):\n",
    "    start_idx = response.index(start)\n",
    "    end_idx = response[::-1].index(end)\n",
    "    if end_idx == 0:\n",
    "        string = response[start_idx:]\n",
    "    else:\n",
    "        string = response[start_idx:-end_idx]\n",
    "    return json.loads(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c1414799-02dc-4ebf-9f18-45d7ae83c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for param in params:\n",
    "    chat = ChatOpenAI(model=param['model'], \n",
    "                      temperature=param['temperature'],\n",
    "                     )\n",
    "    \n",
    "    # define prompt and chat\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"You are {param['role']}.\" + \"Extract and analyze the test functions from the codes:\\n\\n{context}\"),\n",
    "        (\"system\", f\"Here is the Machine Learning system testing checklist delimited by triple quotes '''{param['checklist']}'''\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ])\n",
    "    \n",
    "    # combine prompt, chat and doc\n",
    "    chain = create_stuff_documents_chain(chat, prompt) \n",
    "\n",
    "    # evaluation test run\n",
    "    for i in range(num_test_runs):\n",
    "        result = dict()\n",
    "        report = chain.invoke({\n",
    "            \"context\": all_splits,\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=param['user_prompt'])\n",
    "            ],\n",
    "        })\n",
    "\n",
    "        result['report'] = report\n",
    "        result['Param_Set_ID'] = param['Param_Set_ID']\n",
    "        result['Test_No'] = i+1\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "579b6e45-5af0-4115-bb16-0b1a9df53b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    results[i]['report'] = extract_json(results[i]['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4a8e944a-802b-4ee1-beae-438d8178f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[2]['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d66d396d-8665-48a1-bd57-299850165e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th>Test_No</th>\n",
       "      <th>Checklist Evaluation</th>\n",
       "      <th>Completeness Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 2, 'Numbe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Param_Set_ID  Test_No                               Checklist Evaluation  \\\n",
       "0             0        1  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "1             0        2  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "2             0        3  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "3             0        4  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "4             0        5  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "\n",
       "                                  Completeness Score  \n",
       "0  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "1  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "2  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "3  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "4  {'Number of satisfied requirements': 2, 'Numbe...  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = pd.concat([results_df, results_df['report'].apply(pd.Series)], axis=1)\n",
    "results_df = results_df.drop(columns='report')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846cf7e-2783-41e0-a190-a9a5a4952946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ce51c6-0dbf-4fa7-8722-5bef38e0224a",
   "metadata": {},
   "source": [
    "## Result & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc750f68-4fa7-4264-a270-2f3cc0ea667c",
   "metadata": {},
   "source": [
    "The evaluation will be based on 2 metrics calculated from the response:\n",
    "- Completeness Score distribution: The distribution of the `num_test_runs` completeness scores per each set of parameters\n",
    "- Consistency Score: Out of all `checklist` items, the proportion of results remain consistent among `num_test_runs` runs per each set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "22ea8a4d-1f08-4f4d-9c80-4dc56ac16b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_score_df = results_df.drop(columns='Checklist Evaluation')\n",
    "completeness_score_df = pd.concat([completeness_score_df, completeness_score_df['Completeness Score'].apply(pd.Series)], axis=1)\n",
    "completeness_score_df['completeness_score'] = completeness_score_df['Number of satisfied requirements'] / completeness_score_df['Number of requirements']\n",
    "completeness_score_df = completeness_score_df.pivot(index='Test_No', columns='Param_Set_ID', values='completeness_score')\n",
    "# completeness_score_df.reset_index()\n",
    "# completeness_score_df.columns.name = 'completeness_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "69617811-0bde-48d2-8604-5ba692a65df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_No</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Test_No          1     2     3     4    5\n",
       "Param_Set_ID                             \n",
       "0             0.75  0.75  0.75  0.75  0.5"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_score_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ccd1a25b-674b-4c77-8b32-88ec6600a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_df = results_df.drop(columns='Completeness Score')\n",
    "consistency_df = consistency_df.explode('Checklist Evaluation')\n",
    "consistency_df = pd.concat([consistency_df, consistency_df['Checklist Evaluation'].apply(pd.Series)], axis=1)\n",
    "consistency_df = consistency_df.pivot(index=['Param_Set_ID', 'ID'], columns=['Test_No'], values=['Evaluation'])['Evaluation']\n",
    "consistency_df['consistency'] = consistency_df.eq(consistency_df.iloc[:, 0], axis=0).all(1)\n",
    "# consistency_df = consistency_df.reset_index().drop(columns=['Param_Set_ID'])\n",
    "consistency_df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "28c90383-e3c8-44a9-83a2-344495be26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>2.1</th>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Not Satisfied</td>\n",
       "      <td>Not Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Not Satisfied</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1</th>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    1                    2  \\\n",
       "Param_Set_ID ID                                              \n",
       "0            2.1            Satisfied            Satisfied   \n",
       "             2.2  Partially Satisfied        Not Satisfied   \n",
       "             3.1            Satisfied            Satisfied   \n",
       "             3.2  Partially Satisfied  Partially Satisfied   \n",
       "\n",
       "                                    3                    4  \\\n",
       "Param_Set_ID ID                                              \n",
       "0            2.1            Satisfied            Satisfied   \n",
       "             2.2        Not Satisfied            Satisfied   \n",
       "             3.1            Satisfied            Satisfied   \n",
       "             3.2  Partially Satisfied  Partially Satisfied   \n",
       "\n",
       "                                    5  consistency  \n",
       "Param_Set_ID ID                                     \n",
       "0            2.1            Satisfied         True  \n",
       "             2.2        Not Satisfied        False  \n",
       "             3.1            Satisfied         True  \n",
       "             3.2  Partially Satisfied         True  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consistency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ca45a592-7490-4f86-8357-0707ef81e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consistency_df = consistency_df.reset_index().rename(columns={\"ID\": \"Checklist_ID\"})\n",
    "# consistency_df = consistency_df.groupby(['Param_Set_ID']).mean('consistency')\n",
    "# consistency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c0b4b-ca68-4d44-9cb7-977e08abadb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test-creation]",
   "language": "python",
   "name": "conda-env-test-creation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
