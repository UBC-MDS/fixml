{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b9be5c-c6c2-4fce-9bca-815f8772443a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78741377-167e-41d6-9542-c3593c0079ff",
   "metadata": {},
   "source": [
    "This Jupyter notebook is a tool to evaluate the consistency of ML Test Evaluation performed by ChatGPT based on the research paper (Alexander, R., Katz, L., Moore, C., & Schwartz, Z. (2023)). \\\n",
    "It serves the purpose of evaluating the application performance before and after checklist modification, and evaluating the application performance upon model setting changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427397a-321d-4ba8-ba63-512e18eea528",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb67c7b-0b04-4f5f-a42b-7b31dcd963bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../test_creation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b6521a-4c59-4c34-ae5f-720706d2f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import TestEvaluator\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4a70a-f520-4a9e-83b0-92df5a10e82a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c1246-cb79-443c-a833-1784f4e25da3",
   "metadata": {},
   "source": [
    "Please specify the `test_functions_directory` below to load the ML test code base for the evaluation.\\\n",
    "The loaded test functions will be further split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74036e8d-1dee-459b-bdf7-fa797b262e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_functions_directory = '../../../lightfm/tests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828448c6-8bd4-448d-8964-cda9e3481f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2139ca-98d3-4253-a2e1-3ecdce1a1018",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03e63c-fb18-4361-b117-aa2355b7f5bb",
   "metadata": {},
   "source": [
    "Please specify the parameters, e.g. checklist, and the corresponding models to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4408d48-9590-444c-8725-52b06363fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210373f1-9354-434c-9103-5c4b767b14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperatures = [0.1]\n",
    "# models = ['gpt-3.5-turbo']\n",
    "# roles = ['a senior machine learning engineer who specializes in performing Machine Learning system testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc5a229-892d-47de-b882-cdb9b5ae154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_message = \"\"\"\n",
    "# Your task is to answer each question in the checklist using only the provided test functions. Do not disclose your work for this step.\n",
    "# Then, decide the completion score in a fraction format based on your answers.\n",
    "# Desired JSON format:\n",
    "# {\n",
    "#     \"Checklist Evaluation\":\n",
    "#         \"ID\": \n",
    "#         \"Requirement\": -||-\n",
    "#         \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\n",
    "#     \"Completeness Score\": \n",
    "#         \"Number of satisfied requirements\":\n",
    "#         \"Number of partially satisfied requirements\":\n",
    "#         \"Number of not satisfied requirements\":\n",
    "#         \"Number of requirements\":\n",
    "# }\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa645b9-5293-4632-8278-b597c714eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_prompts = [human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457946ba-0723-45a1-9491-c40ede92992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_real_before = './checklist_demo1.yaml'\n",
    "# # Before Prompt Engineering\n",
    "# '''\n",
    "# 2.1: Verify the function for loading data files load the file if the files exists with the right format, and doesn't load the file if it doesn't exist, and that it returns the expected results.\n",
    "# 2.2: Verify the functions for saving data and figures can write as expected. They should check the if the write operation is successfully carried out, and the content is in an expected format.\n",
    "# 3.1: Ensure that all data files are non-empty and contain the necessary data to proceed with the analysis or processing tasks.\n",
    "# 3.2: Check that the data to be ingested is in the format expected by the processing algorithms (e.g., Is the CSV loaded as a `pd.DataFrame`? Is the image file loaded as a `np.array`, or a `PIL.Image`?) and that their structure matches the expected schema, any present.\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a34d68-21a8-4667-a836-6d7f9d9c23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist_real_after = './checklist_demo2.yaml'\n",
    "# # After Prompt Engineering\n",
    "# \"\"\"\n",
    "# 2.1: Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\n",
    "# 2.2: Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\n",
    "# 3.1: Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\n",
    "# 3.2: Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46898c0d-dd18-4812-a6ba-fced01aabcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklists = [checklist_real_after] # checklist_real_before, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eccb8ce-962f-47f9-9693-d30a32dff312",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'Param_Set_ID': i,\n",
    "        'checklist': item[0],\n",
    "        # 'temperature': item[1],\n",
    "        # 'model': item[2],\n",
    "        # 'role': item[3],\n",
    "        # 'user_prompt': item[4],\n",
    "    } for i, item in enumerate(itertools.product(\n",
    "        checklists,\n",
    "        # temperatures, \n",
    "        # models,\n",
    "        # roles,\n",
    "        # user_prompts,\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fccbbab1-65de-495e-8071-38021e67cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th>checklist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./checklist_demo2.yaml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Param_Set_ID               checklist\n",
       "0             0  ./checklist_demo2.yaml"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cdd4a-6afe-4b39-8a65-46261ebaab16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9dee5f-fe3a-42ec-9daf-28ca7830d388",
   "metadata": {},
   "source": [
    "## API Running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ba74b-6ac9-4d6b-a11a-71f17a21614f",
   "metadata": {},
   "source": [
    "Incorporate the data, prompts and parameters, feed into OpenAI API for test runs and fetch responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbc27df-db63-4e57-ab9d-3d6121327d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_runs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacf4e29-eb96-4fac-b340-1c9dbe328477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_json(response, start='{', end='}'):\n",
    "#     start_idx = response.index(start)\n",
    "#     end_idx = response[::-1].index(end)\n",
    "#     if end_idx == 0:\n",
    "#         string = response[start_idx:]\n",
    "#     else:\n",
    "#         string = response[start_idx:-end_idx]\n",
    "#     return json.loads(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1414799-02dc-4ebf-9f18-45d7ae83c091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_fast_functions.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▊                                                                               | 1/6 [00:06<00:32,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_movielens.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████▋                                                               | 2/6 [00:46<01:43, 25.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_datasets.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████▌                                               | 3/6 [00:54<00:54, 18.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_cross_validation.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████▎                               | 4/6 [01:04<00:29, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_evaluation.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████████████▏               | 5/6 [01:14<00:12, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_data.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:21<00:00, 13.54s/it]\n",
      "  0%|                                                                                                       | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../lightfm/tests/test_fast_functions.py\n",
      "# splits: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/6 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 22 (char 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_test_runs):\n\u001b[1;32m      8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreport\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluation_result\n\u001b[1;32m     12\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParam_Set_ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParam_Set_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/mds/dsci591/test-creation/src/checklist_eval/../test_creation/analyze.py:219\u001b[0m, in \u001b[0;36mTestEvaluator.evaluate\u001b[0;34m(self, on_file)\u001b[0m\n\u001b[1;32m    217\u001b[0m response, history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_evaluation_response()  \u001b[38;5;66;03m# FIXME: it sometimes tests only part of the checklist items\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# print(response)\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# print(report)\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m report:\n",
      "File \u001b[0;32m~/Documents/mds/dsci591/test-creation/src/checklist_eval/../test_creation/analyze.py:208\u001b[0m, in \u001b[0;36mTestEvaluator.extract_json\u001b[0;34m(self, response, start, end)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     string \u001b[38;5;241m=\u001b[39m response[start_idx:\u001b[38;5;241m-\u001b[39mend_idx]\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test-creation/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/test-creation/lib/python3.12/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 22 (char 21)"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for param in params:\n",
    "    # evaluation test run\n",
    "    evaluator = TestEvaluator(test_functions_directory)\n",
    "    evaluator.load_checklist(param['checklist'])\n",
    "    \n",
    "    for i in range(num_test_runs):\n",
    "        result = dict()\n",
    "        evaluator.evaluate()\n",
    "\n",
    "        result['report'] = evaluator.evaluation_result\n",
    "        result['Param_Set_ID'] = param['Param_Set_ID']\n",
    "        result['Test_No'] = i+1\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b49bdf9-84ba-4e80-832a-cb66b19c05fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': '../../../lightfm/tests/test_fast_functions.py',\n",
       "  'report': [{'ID': '2.1',\n",
       "    'Title': 'Ensure Data File Loads as Expected',\n",
       "    'Requirement': 'Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.',\n",
       "    'Observation': 'The test functions do not directly involve loading data files. They operate on a sparse matrix created from a numpy array.',\n",
       "    'Functions': ['test_in_positives'],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_fast_functions.py'},\n",
       "   {'ID': '2.2',\n",
       "    'Title': 'Ensure Saving Data/Figures Function Works as Expected',\n",
       "    'Requirement': 'Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.',\n",
       "    'Observation': 'The test functions do not involve saving data or figures.',\n",
       "    'Functions': ['test_in_positives'],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_fast_functions.py'},\n",
       "   {'ID': '3.1',\n",
       "    'Title': 'Files Contain Data',\n",
       "    'Requirement': 'Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.',\n",
       "    'Observation': 'The test functions do not involve reading data from external files.',\n",
       "    'Functions': ['test_in_positives'],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_fast_functions.py'},\n",
       "   {'ID': '3.2',\n",
       "    'Title': 'Data in the Expected Format',\n",
       "    'Requirement': 'Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.',\n",
       "    'Observation': 'The test functions operate on a sparse matrix created from a numpy array, ensuring the data is in the expected format for the algorithms used.',\n",
       "    'Functions': ['test_in_positives'],\n",
       "    'Evaluation': 'Partially Satisfied',\n",
       "    'Score': 0.5,\n",
       "    'file': '../../../lightfm/tests/test_fast_functions.py'}],\n",
       "  'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='\\n            Your task is to answer each question in the checklist using only the provided test functions.\\n            If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\\n            Output a JSON format:\\n                {\\n                    \"ID\": \\n                    \"Title\":\\n                    \"Requirement\":\\n                    \"Observation\":\\n                    \"Functions\": [ ... ]\\n                    \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\\n                    \"Score\": (1 for Satisfied / 0.5 for Partially Satisfied / 0 for Not Satisfied)\\n                }\\n        '), AIMessage(content='{\\n    \"checks\": [\\n        {\\n            \"ID\": \"2.1\",\\n            \"Title\": \"Ensure Data File Loads as Expected\",\\n            \"Requirement\": \"Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\",\\n            \"Observation\": \"The test functions do not directly involve loading data files. They operate on a sparse matrix created from a numpy array.\",\\n            \"Functions\": [\"test_in_positives\"],\\n            \"Evaluation\": \"Not Satisfied\",\\n            \"Score\": 0\\n        },\\n        {\\n            \"ID\": \"2.2\",\\n            \"Title\": \"Ensure Saving Data/Figures Function Works as Expected\",\\n            \"Requirement\": \"Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\",\\n            \"Observation\": \"The test functions do not involve saving data or figures.\",\\n            \"Functions\": [\"test_in_positives\"],\\n            \"Evaluation\": \"Not Satisfied\",\\n            \"Score\": 0\\n        },\\n        {\\n            \"ID\": \"3.1\",\\n            \"Title\": \"Files Contain Data\",\\n            \"Requirement\": \"Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\",\\n            \"Observation\": \"The test functions do not involve reading data from external files.\",\\n            \"Functions\": [\"test_in_positives\"],\\n            \"Evaluation\": \"Not Satisfied\",\\n            \"Score\": 0\\n        },\\n        {\\n            \"ID\": \"3.2\",\\n            \"Title\": \"Data in the Expected Format\",\\n            \"Requirement\": \"Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\",\\n            \"Observation\": \"The test functions operate on a sparse matrix created from a numpy array, ensuring the data is in the expected format for the algorithms used.\",\\n            \"Functions\": [\"test_in_positives\"],\\n            \"Evaluation\": \"Partially Satisfied\",\\n            \"Score\": 0.5\\n        }\\n    ]\\n}')])},\n",
       " {'file': '../../../lightfm/tests/test_movielens.py',\n",
       "  'report': [{'ID': '2.1',\n",
       "    'Title': 'Ensure Data File Loads as Expected',\n",
       "    'Requirement': 'Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.',\n",
       "    'Observation': \"The test functions 'test_movielens_accuracy', 'test_logistic_precision', 'test_bpr_precision', 'test_bpr_precision_multithreaded', 'test_warp_precision', 'test_warp_precision_high_interaction_values', 'test_bpr_precision_high_interaction_values', 'test_warp_precision_multithreaded', 'test_warp_precision_adadelta', 'test_warp_precision_adadelta_multithreaded', 'test_warp_precision_max_sampled', 'test_warp_kos_precision', 'test_warp_stability', 'test_movielens_genre_accuracy', 'test_get_representations', 'test_movielens_both_accuracy', 'test_movielens_accuracy_fit', 'test_movielens_accuracy_pickle', 'test_movielens_accuracy_resume', 'test_movielens_accuracy_sample_weights', 'test_movielens_accuracy_sample_weights_grad_accumulation', 'test_state_reset', 'test_user_supplied_features_accuracy', 'test_zeros_negative_accuracy', 'test_zero_weights_accuracy', 'test_hogwild_accuracy', 'test_movielens_excessive_regularization', 'test_overfitting', 'test_regularization', 'test_training_schedules', 'test_random_state_fixing', 'test_random_state_advanced', and 'test_sklearn_cv' involve loading data, training models, and evaluating results which indirectly test the data-loading functionality.\",\n",
       "    'Functions': ['test_movielens_accuracy',\n",
       "     'test_logistic_precision',\n",
       "     'test_bpr_precision',\n",
       "     'test_bpr_precision_multithreaded',\n",
       "     'test_warp_precision',\n",
       "     'test_warp_precision_high_interaction_values',\n",
       "     'test_bpr_precision_high_interaction_values',\n",
       "     'test_warp_precision_multithreaded',\n",
       "     'test_warp_precision_adadelta',\n",
       "     'test_warp_precision_adadelta_multithreaded',\n",
       "     'test_warp_precision_max_sampled',\n",
       "     'test_warp_kos_precision',\n",
       "     'test_warp_stability',\n",
       "     'test_movielens_genre_accuracy',\n",
       "     'test_get_representations',\n",
       "     'test_movielens_both_accuracy',\n",
       "     'test_movielens_accuracy_fit',\n",
       "     'test_movielens_accuracy_pickle',\n",
       "     'test_movielens_accuracy_resume',\n",
       "     'test_movielens_accuracy_sample_weights',\n",
       "     'test_movielens_accuracy_sample_weights_grad_accumulation',\n",
       "     'test_state_reset',\n",
       "     'test_user_supplied_features_accuracy',\n",
       "     'test_zeros_negative_accuracy',\n",
       "     'test_zero_weights_accuracy',\n",
       "     'test_hogwild_accuracy',\n",
       "     'test_movielens_excessive_regularization',\n",
       "     'test_overfitting',\n",
       "     'test_regularization',\n",
       "     'test_training_schedules',\n",
       "     'test_random_state_fixing',\n",
       "     'test_random_state_advanced',\n",
       "     'test_sklearn_cv'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_movielens.py'},\n",
       "   {'ID': '2.2',\n",
       "    'Title': 'Ensure Saving Data/Figures Function Works as Expected',\n",
       "    'Requirement': 'Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.',\n",
       "    'Observation': 'The provided test functions do not directly test the saving of data or figures. Therefore, this requirement cannot be evaluated based on the existing test functions.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Applicable',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_movielens.py'},\n",
       "   {'ID': '3.1',\n",
       "    'Title': 'Files Contain Data',\n",
       "    'Requirement': 'Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.',\n",
       "    'Observation': \"The test functions 'test_movielens_accuracy', 'test_logistic_precision', 'test_bpr_precision', 'test_bpr_precision_multithreaded', 'test_warp_precision', 'test_warp_precision_high_interaction_values', 'test_bpr_precision_high_interaction_values', 'test_warp_precision_multithreaded', 'test_warp_precision_adadelta', 'test_warp_precision_adadelta_multithreaded', 'test_warp_precision_max_sampled', 'test_warp_kos_precision', 'test_warp_stability', 'test_movielens_genre_accuracy', 'test_get_representations', 'test_movielens_both_accuracy', 'test_movielens_accuracy_fit', 'test_movielens_accuracy_pickle', 'test_movielens_accuracy_resume', 'test_movielens_accuracy_sample_weights', 'test_movielens_accuracy_sample_weights_grad_accumulation', 'test_state_reset', 'test_user_supplied_features_accuracy', 'test_zeros_negative_accuracy', 'test_zero_weights_accuracy', 'test_hogwild_accuracy', 'test_movielens_excessive_regularization', 'test_overfitting', 'test_regularization', 'test_training_schedules', 'test_random_state_fixing', 'test_random_state_advanced', and 'test_sklearn_cv' involve loading data, training models, and evaluating results which indirectly test the presence of data in the files.\",\n",
       "    'Functions': ['test_movielens_accuracy',\n",
       "     'test_logistic_precision',\n",
       "     'test_bpr_precision',\n",
       "     'test_bpr_precision_multithreaded',\n",
       "     'test_warp_precision',\n",
       "     'test_warp_precision_high_interaction_values',\n",
       "     'test_bpr_precision_high_interaction_values',\n",
       "     'test_warp_precision_multithreaded',\n",
       "     'test_warp_precision_adadelta',\n",
       "     'test_warp_precision_adadelta_multithreaded',\n",
       "     'test_warp_precision_max_sampled',\n",
       "     'test_warp_kos_precision',\n",
       "     'test_warp_stability',\n",
       "     'test_movielens_genre_accuracy',\n",
       "     'test_get_representations',\n",
       "     'test_movielens_both_accuracy',\n",
       "     'test_movielens_accuracy_fit',\n",
       "     'test_movielens_accuracy_pickle',\n",
       "     'test_movielens_accuracy_resume',\n",
       "     'test_movielens_accuracy_sample_weights',\n",
       "     'test_movielens_accuracy_sample_weights_grad_accumulation',\n",
       "     'test_state_reset',\n",
       "     'test_user_supplied_features_accuracy',\n",
       "     'test_zeros_negative_accuracy',\n",
       "     'test_zero_weights_accuracy',\n",
       "     'test_hogwild_accuracy',\n",
       "     'test_movielens_excessive_regularization',\n",
       "     'test_overfitting',\n",
       "     'test_regularization',\n",
       "     'test_training_schedules',\n",
       "     'test_random_state_fixing',\n",
       "     'test_random_state_advanced',\n",
       "     'test_sklearn_cv'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_movielens.py'},\n",
       "   {'ID': '3.2',\n",
       "    'Title': 'Data in the Expected Format',\n",
       "    'Requirement': 'Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.',\n",
       "    'Observation': \"The test functions 'test_movielens_accuracy', 'test_logistic_precision', 'test_bpr_precision', 'test_bpr_precision_multithreaded', 'test_warp_precision', 'test_warp_precision_high_interaction_values', 'test_bpr_precision_high_interaction_values', 'test_warp_precision_multithreaded', 'test_warp_precision_adadelta', 'test_warp_precision_adadelta_multithreaded', 'test_warp_precision_max_sampled', 'test_warp_kos_precision', 'test_warp_stability', 'test_movielens_genre_accuracy', 'test_get_representations', 'test_movielens_both_accuracy', 'test_movielens_accuracy_fit', 'test_movielens_accuracy_pickle', 'test_movielens_accuracy_resume', 'test_movielens_accuracy_sample_weights', 'test_movielens_accuracy_sample_weights_grad_accumulation', 'test_state_reset', 'test_user_supplied_features_accuracy', 'test_zeros_negative_accuracy', 'test_zero_weights_accuracy', 'test_hogwild_accuracy', 'test_movielens_excessive_regularization', 'test_overfitting', 'test_regularization', 'test_training_schedules', 'test_random_state_fixing', 'test_random_state_advanced', and 'test_sklearn_cv' involve loading data, training models, and evaluating results which indirectly test the format and schema of the data.\",\n",
       "    'Functions': ['test_movielens_accuracy',\n",
       "     'test_logistic_precision',\n",
       "     'test_bpr_precision',\n",
       "     'test_bpr_precision_multithreaded',\n",
       "     'test_warp_precision',\n",
       "     'test_warp_precision_high_interaction_values',\n",
       "     'test_bpr_precision_high_interaction_values',\n",
       "     'test_warp_precision_multithreaded',\n",
       "     'test_warp_precision_adadelta',\n",
       "     'test_warp_precision_adadelta_multithreaded',\n",
       "     'test_warp_precision_max_sampled',\n",
       "     'test_warp_kos_precision',\n",
       "     'test_warp_stability',\n",
       "     'test_movielens_genre_accuracy',\n",
       "     'test_get_representations',\n",
       "     'test_movielens_both_accuracy',\n",
       "     'test_movielens_accuracy_fit',\n",
       "     'test_movielens_accuracy_pickle',\n",
       "     'test_movielens_accuracy_resume',\n",
       "     'test_movielens_accuracy_sample_weights',\n",
       "     'test_movielens_accuracy_sample_weights_grad_accumulation',\n",
       "     'test_state_reset',\n",
       "     'test_user_supplied_features_accuracy',\n",
       "     'test_zeros_negative_accuracy',\n",
       "     'test_zero_weights_accuracy',\n",
       "     'test_hogwild_accuracy',\n",
       "     'test_movielens_excessive_regularization',\n",
       "     'test_overfitting',\n",
       "     'test_regularization',\n",
       "     'test_training_schedules',\n",
       "     'test_random_state_fixing',\n",
       "     'test_random_state_advanced',\n",
       "     'test_sklearn_cv'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_movielens.py'}],\n",
       "  'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='\\n            Your task is to answer each question in the checklist using only the provided test functions.\\n            If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\\n            Output a JSON format:\\n                {\\n                    \"ID\": \\n                    \"Title\":\\n                    \"Requirement\":\\n                    \"Observation\":\\n                    \"Functions\": [ ... ]\\n                    \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\\n                    \"Score\": (1 for Satisfied / 0.5 for Partially Satisfied / 0 for Not Satisfied)\\n                }\\n        '), AIMessage(content='```json\\n[\\n    {\\n        \"ID\": \"2.1\",\\n        \"Title\": \"Ensure Data File Loads as Expected\",\\n        \"Requirement\": \"Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\",\\n        \"Observation\": \"The test functions \\'test_movielens_accuracy\\', \\'test_logistic_precision\\', \\'test_bpr_precision\\', \\'test_bpr_precision_multithreaded\\', \\'test_warp_precision\\', \\'test_warp_precision_high_interaction_values\\', \\'test_bpr_precision_high_interaction_values\\', \\'test_warp_precision_multithreaded\\', \\'test_warp_precision_adadelta\\', \\'test_warp_precision_adadelta_multithreaded\\', \\'test_warp_precision_max_sampled\\', \\'test_warp_kos_precision\\', \\'test_warp_stability\\', \\'test_movielens_genre_accuracy\\', \\'test_get_representations\\', \\'test_movielens_both_accuracy\\', \\'test_movielens_accuracy_fit\\', \\'test_movielens_accuracy_pickle\\', \\'test_movielens_accuracy_resume\\', \\'test_movielens_accuracy_sample_weights\\', \\'test_movielens_accuracy_sample_weights_grad_accumulation\\', \\'test_state_reset\\', \\'test_user_supplied_features_accuracy\\', \\'test_zeros_negative_accuracy\\', \\'test_zero_weights_accuracy\\', \\'test_hogwild_accuracy\\', \\'test_movielens_excessive_regularization\\', \\'test_overfitting\\', \\'test_regularization\\', \\'test_training_schedules\\', \\'test_random_state_fixing\\', \\'test_random_state_advanced\\', and \\'test_sklearn_cv\\' involve loading data, training models, and evaluating results which indirectly test the data-loading functionality.\",\\n        \"Functions\": [\\n            \"test_movielens_accuracy\",\\n            \"test_logistic_precision\",\\n            \"test_bpr_precision\",\\n            \"test_bpr_precision_multithreaded\",\\n            \"test_warp_precision\",\\n            \"test_warp_precision_high_interaction_values\",\\n            \"test_bpr_precision_high_interaction_values\",\\n            \"test_warp_precision_multithreaded\",\\n            \"test_warp_precision_adadelta\",\\n            \"test_warp_precision_adadelta_multithreaded\",\\n            \"test_warp_precision_max_sampled\",\\n            \"test_warp_kos_precision\",\\n            \"test_warp_stability\",\\n            \"test_movielens_genre_accuracy\",\\n            \"test_get_representations\",\\n            \"test_movielens_both_accuracy\",\\n            \"test_movielens_accuracy_fit\",\\n            \"test_movielens_accuracy_pickle\",\\n            \"test_movielens_accuracy_resume\",\\n            \"test_movielens_accuracy_sample_weights\",\\n            \"test_movielens_accuracy_sample_weights_grad_accumulation\",\\n            \"test_state_reset\",\\n            \"test_user_supplied_features_accuracy\",\\n            \"test_zeros_negative_accuracy\",\\n            \"test_zero_weights_accuracy\",\\n            \"test_hogwild_accuracy\",\\n            \"test_movielens_excessive_regularization\",\\n            \"test_overfitting\",\\n            \"test_regularization\",\\n            \"test_training_schedules\",\\n            \"test_random_state_fixing\",\\n            \"test_random_state_advanced\",\\n            \"test_sklearn_cv\"\\n        ],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    },\\n    {\\n        \"ID\": \"2.2\",\\n        \"Title\": \"Ensure Saving Data/Figures Function Works as Expected\",\\n        \"Requirement\": \"Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\",\\n        \"Observation\": \"The provided test functions do not directly test the saving of data or figures. Therefore, this requirement cannot be evaluated based on the existing test functions.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Applicable\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.1\",\\n        \"Title\": \"Files Contain Data\",\\n        \"Requirement\": \"Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\",\\n        \"Observation\": \"The test functions \\'test_movielens_accuracy\\', \\'test_logistic_precision\\', \\'test_bpr_precision\\', \\'test_bpr_precision_multithreaded\\', \\'test_warp_precision\\', \\'test_warp_precision_high_interaction_values\\', \\'test_bpr_precision_high_interaction_values\\', \\'test_warp_precision_multithreaded\\', \\'test_warp_precision_adadelta\\', \\'test_warp_precision_adadelta_multithreaded\\', \\'test_warp_precision_max_sampled\\', \\'test_warp_kos_precision\\', \\'test_warp_stability\\', \\'test_movielens_genre_accuracy\\', \\'test_get_representations\\', \\'test_movielens_both_accuracy\\', \\'test_movielens_accuracy_fit\\', \\'test_movielens_accuracy_pickle\\', \\'test_movielens_accuracy_resume\\', \\'test_movielens_accuracy_sample_weights\\', \\'test_movielens_accuracy_sample_weights_grad_accumulation\\', \\'test_state_reset\\', \\'test_user_supplied_features_accuracy\\', \\'test_zeros_negative_accuracy\\', \\'test_zero_weights_accuracy\\', \\'test_hogwild_accuracy\\', \\'test_movielens_excessive_regularization\\', \\'test_overfitting\\', \\'test_regularization\\', \\'test_training_schedules\\', \\'test_random_state_fixing\\', \\'test_random_state_advanced\\', and \\'test_sklearn_cv\\' involve loading data, training models, and evaluating results which indirectly test the presence of data in the files.\",\\n        \"Functions\": [\\n            \"test_movielens_accuracy\",\\n            \"test_logistic_precision\",\\n            \"test_bpr_precision\",\\n            \"test_bpr_precision_multithreaded\",\\n            \"test_warp_precision\",\\n            \"test_warp_precision_high_interaction_values\",\\n            \"test_bpr_precision_high_interaction_values\",\\n            \"test_warp_precision_multithreaded\",\\n            \"test_warp_precision_adadelta\",\\n            \"test_warp_precision_adadelta_multithreaded\",\\n            \"test_warp_precision_max_sampled\",\\n            \"test_warp_kos_precision\",\\n            \"test_warp_stability\",\\n            \"test_movielens_genre_accuracy\",\\n            \"test_get_representations\",\\n            \"test_movielens_both_accuracy\",\\n            \"test_movielens_accuracy_fit\",\\n            \"test_movielens_accuracy_pickle\",\\n            \"test_movielens_accuracy_resume\",\\n            \"test_movielens_accuracy_sample_weights\",\\n            \"test_movielens_accuracy_sample_weights_grad_accumulation\",\\n            \"test_state_reset\",\\n            \"test_user_supplied_features_accuracy\",\\n            \"test_zeros_negative_accuracy\",\\n            \"test_zero_weights_accuracy\",\\n            \"test_hogwild_accuracy\",\\n            \"test_movielens_excessive_regularization\",\\n            \"test_overfitting\",\\n            \"test_regularization\",\\n            \"test_training_schedules\",\\n            \"test_random_state_fixing\",\\n            \"test_random_state_advanced\",\\n            \"test_sklearn_cv\"\\n        ],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    },\\n    {\\n        \"ID\": \"3.2\",\\n        \"Title\": \"Data in the Expected Format\",\\n        \"Requirement\": \"Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\",\\n        \"Observation\": \"The test functions \\'test_movielens_accuracy\\', \\'test_logistic_precision\\', \\'test_bpr_precision\\', \\'test_bpr_precision_multithreaded\\', \\'test_warp_precision\\', \\'test_warp_precision_high_interaction_values\\', \\'test_bpr_precision_high_interaction_values\\', \\'test_warp_precision_multithreaded\\', \\'test_warp_precision_adadelta\\', \\'test_warp_precision_adadelta_multithreaded\\', \\'test_warp_precision_max_sampled\\', \\'test_warp_kos_precision\\', \\'test_warp_stability\\', \\'test_movielens_genre_accuracy\\', \\'test_get_representations\\', \\'test_movielens_both_accuracy\\', \\'test_movielens_accuracy_fit\\', \\'test_movielens_accuracy_pickle\\', \\'test_movielens_accuracy_resume\\', \\'test_movielens_accuracy_sample_weights\\', \\'test_movielens_accuracy_sample_weights_grad_accumulation\\', \\'test_state_reset\\', \\'test_user_supplied_features_accuracy\\', \\'test_zeros_negative_accuracy\\', \\'test_zero_weights_accuracy\\', \\'test_hogwild_accuracy\\', \\'test_movielens_excessive_regularization\\', \\'test_overfitting\\', \\'test_regularization\\', \\'test_training_schedules\\', \\'test_random_state_fixing\\', \\'test_random_state_advanced\\', and \\'test_sklearn_cv\\' involve loading data, training models, and evaluating results which indirectly test the format and schema of the data.\",\\n        \"Functions\": [\\n            \"test_movielens_accuracy\",\\n            \"test_logistic_precision\",\\n            \"test_bpr_precision\",\\n            \"test_bpr_precision_multithreaded\",\\n            \"test_warp_precision\",\\n            \"test_warp_precision_high_interaction_values\",\\n            \"test_bpr_precision_high_interaction_values\",\\n            \"test_warp_precision_multithreaded\",\\n            \"test_warp_precision_adadelta\",\\n            \"test_warp_precision_adadelta_multithreaded\",\\n            \"test_warp_precision_max_sampled\",\\n            \"test_warp_kos_precision\",\\n            \"test_warp_stability\",\\n            \"test_movielens_genre_accuracy\",\\n            \"test_get_representations\",\\n            \"test_movielens_both_accuracy\",\\n            \"test_movielens_accuracy_fit\",\\n            \"test_movielens_accuracy_pickle\",\\n            \"test_movielens_accuracy_resume\",\\n            \"test_movielens_accuracy_sample_weights\",\\n            \"test_movielens_accuracy_sample_weights_grad_accumulation\",\\n            \"test_state_reset\",\\n            \"test_user_supplied_features_accuracy\",\\n            \"test_zeros_negative_accuracy\",\\n            \"test_zero_weights_accuracy\",\\n            \"test_hogwild_accuracy\",\\n            \"test_movielens_excessive_regularization\",\\n            \"test_overfitting\",\\n            \"test_regularization\",\\n            \"test_training_schedules\",\\n            \"test_random_state_fixing\",\\n            \"test_random_state_advanced\",\\n            \"test_sklearn_cv\"\\n        ],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    }\\n]\\n```')])},\n",
       " {'file': '../../../lightfm/tests/test_datasets.py',\n",
       "  'report': [{'ID': '2.1',\n",
       "    'Title': 'Ensure Data File Loads as Expected',\n",
       "    'Requirement': 'Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.',\n",
       "    'Observation': \"The test functions 'test_basic_fetching_movielens' and 'test_basic_fetching_stackexchange' validate the loading of data files from the 'fetch_movielens' and 'fetch_stackexchange' functions, respectively.\",\n",
       "    'Functions': ['test_basic_fetching_movielens',\n",
       "     'test_basic_fetching_stackexchange'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_datasets.py'},\n",
       "   {'ID': '2.2',\n",
       "    'Title': 'Ensure Saving Data/Figures Function Works as Expected',\n",
       "    'Requirement': 'Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.',\n",
       "    'Observation': 'The provided test functions do not directly test saving data or figures. Therefore, this requirement cannot be evaluated based on the available test functions.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_datasets.py'},\n",
       "   {'ID': '3.1',\n",
       "    'Title': 'Files Contain Data',\n",
       "    'Requirement': 'Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.',\n",
       "    'Observation': \"The test functions 'test_basic_fetching_movielens' and 'test_basic_fetching_stackexchange' validate the presence of data in the fetched datasets by checking the shapes and non-zero elements of the train and test matrices.\",\n",
       "    'Functions': ['test_basic_fetching_movielens',\n",
       "     'test_basic_fetching_stackexchange'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_datasets.py'},\n",
       "   {'ID': '3.2',\n",
       "    'Title': 'Data in the Expected Format',\n",
       "    'Requirement': 'Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.',\n",
       "    'Observation': \"The test functions 'test_basic_fetching_movielens' and 'test_basic_fetching_stackexchange' validate the format of the fetched data by checking the types and shapes of the data structures.\",\n",
       "    'Functions': ['test_basic_fetching_movielens',\n",
       "     'test_basic_fetching_stackexchange'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_datasets.py'}],\n",
       "  'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='\\n            Your task is to answer each question in the checklist using only the provided test functions.\\n            If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\\n            Output a JSON format:\\n                {\\n                    \"ID\": \\n                    \"Title\":\\n                    \"Requirement\":\\n                    \"Observation\":\\n                    \"Functions\": [ ... ]\\n                    \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\\n                    \"Score\": (1 for Satisfied / 0.5 for Partially Satisfied / 0 for Not Satisfied)\\n                }\\n        '), AIMessage(content='```json\\n[\\n    {\\n        \"ID\": \"2.1\",\\n        \"Title\": \"Ensure Data File Loads as Expected\",\\n        \"Requirement\": \"Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\",\\n        \"Observation\": \"The test functions \\'test_basic_fetching_movielens\\' and \\'test_basic_fetching_stackexchange\\' validate the loading of data files from the \\'fetch_movielens\\' and \\'fetch_stackexchange\\' functions, respectively.\",\\n        \"Functions\": [\"test_basic_fetching_movielens\", \"test_basic_fetching_stackexchange\"],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    },\\n    {\\n        \"ID\": \"2.2\",\\n        \"Title\": \"Ensure Saving Data/Figures Function Works as Expected\",\\n        \"Requirement\": \"Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\",\\n        \"Observation\": \"The provided test functions do not directly test saving data or figures. Therefore, this requirement cannot be evaluated based on the available test functions.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.1\",\\n        \"Title\": \"Files Contain Data\",\\n        \"Requirement\": \"Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\",\\n        \"Observation\": \"The test functions \\'test_basic_fetching_movielens\\' and \\'test_basic_fetching_stackexchange\\' validate the presence of data in the fetched datasets by checking the shapes and non-zero elements of the train and test matrices.\",\\n        \"Functions\": [\"test_basic_fetching_movielens\", \"test_basic_fetching_stackexchange\"],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    },\\n    {\\n        \"ID\": \"3.2\",\\n        \"Title\": \"Data in the Expected Format\",\\n        \"Requirement\": \"Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\",\\n        \"Observation\": \"The test functions \\'test_basic_fetching_movielens\\' and \\'test_basic_fetching_stackexchange\\' validate the format of the fetched data by checking the types and shapes of the data structures.\",\\n        \"Functions\": [\"test_basic_fetching_movielens\", \"test_basic_fetching_stackexchange\"],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    }\\n]\\n```')])},\n",
       " {'file': '../../../lightfm/tests/test_cross_validation.py',\n",
       "  'report': [{'ID': '2.1',\n",
       "    'Title': 'Ensure Data File Loads as Expected',\n",
       "    'Requirement': 'Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.',\n",
       "    'Observation': \"The test function 'test_random_train_test_split' loads data using 'fetch_movielens' function and performs a train-test split, which implies that the data loading function is working as expected.\",\n",
       "    'Functions': ['test_random_train_test_split'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_cross_validation.py'},\n",
       "   {'ID': '2.2',\n",
       "    'Title': 'Ensure Saving Data/Figures Function Works as Expected',\n",
       "    'Requirement': 'Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.',\n",
       "    'Observation': 'The provided test functions do not directly test saving data or figures; hence, this requirement is not directly addressed.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_cross_validation.py'},\n",
       "   {'ID': '3.1',\n",
       "    'Title': 'Files Contain Data',\n",
       "    'Requirement': 'Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.',\n",
       "    'Observation': \"The test function 'test_random_train_test_split' verifies that the train and test data are disjoint, which implies that the data files contain data.\",\n",
       "    'Functions': ['test_random_train_test_split', '_assert_disjoint'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_cross_validation.py'},\n",
       "   {'ID': '3.2',\n",
       "    'Title': 'Data in the Expected Format',\n",
       "    'Requirement': 'Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.',\n",
       "    'Observation': \"The test function 'test_random_train_test_split' ensures that the train and test data are in the expected format for further processing.\",\n",
       "    'Functions': ['test_random_train_test_split', '_assert_disjoint'],\n",
       "    'Evaluation': 'Satisfied',\n",
       "    'Score': 1,\n",
       "    'file': '../../../lightfm/tests/test_cross_validation.py'}],\n",
       "  'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='\\n            Your task is to answer each question in the checklist using only the provided test functions.\\n            If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\\n            Output a JSON format:\\n                {\\n                    \"ID\": \\n                    \"Title\":\\n                    \"Requirement\":\\n                    \"Observation\":\\n                    \"Functions\": [ ... ]\\n                    \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\\n                    \"Score\": (1 for Satisfied / 0.5 for Partially Satisfied / 0 for Not Satisfied)\\n                }\\n        '), AIMessage(content='```json\\n[\\n    {\\n        \"ID\": \"2.1\",\\n        \"Title\": \"Ensure Data File Loads as Expected\",\\n        \"Requirement\": \"Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\",\\n        \"Observation\": \"The test function \\'test_random_train_test_split\\' loads data using \\'fetch_movielens\\' function and performs a train-test split, which implies that the data loading function is working as expected.\",\\n        \"Functions\": [\"test_random_train_test_split\"],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    },\\n    {\\n        \"ID\": \"2.2\",\\n        \"Title\": \"Ensure Saving Data/Figures Function Works as Expected\",\\n        \"Requirement\": \"Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\",\\n        \"Observation\": \"The provided test functions do not directly test saving data or figures; hence, this requirement is not directly addressed.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.1\",\\n        \"Title\": \"Files Contain Data\",\\n        \"Requirement\": \"Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\",\\n        \"Observation\": \"The test function \\'test_random_train_test_split\\' verifies that the train and test data are disjoint, which implies that the data files contain data.\",\\n        \"Functions\": [\"test_random_train_test_split\", \"_assert_disjoint\"],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    },\\n    {\\n        \"ID\": \"3.2\",\\n        \"Title\": \"Data in the Expected Format\",\\n        \"Requirement\": \"Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\",\\n        \"Observation\": \"The test function \\'test_random_train_test_split\\' ensures that the train and test data are in the expected format for further processing.\",\\n        \"Functions\": [\"test_random_train_test_split\", \"_assert_disjoint\"],\\n        \"Evaluation\": \"Satisfied\",\\n        \"Score\": 1\\n    }\\n]\\n```')])},\n",
       " {'file': '../../../lightfm/tests/test_evaluation.py',\n",
       "  'report': [{'ID': '2.1',\n",
       "    'Title': 'Ensure Data File Loads as Expected',\n",
       "    'Requirement': 'Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.',\n",
       "    'Observation': 'The test functions do not directly load data files. Instead, they generate synthetic data for testing the model. Therefore, this requirement is not directly covered by the provided test functions.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_evaluation.py'},\n",
       "   {'ID': '2.2',\n",
       "    'Title': 'Ensure Saving Data/Figures Function Works as Expected',\n",
       "    'Requirement': 'Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.',\n",
       "    'Observation': 'The test functions do not involve saving data or figures. Therefore, this requirement is not covered by the provided test functions.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_evaluation.py'},\n",
       "   {'ID': '3.1',\n",
       "    'Title': 'Files Contain Data',\n",
       "    'Requirement': 'Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.',\n",
       "    'Observation': 'The test functions do not involve reading data from files. Instead, they generate synthetic data for testing. Therefore, this requirement is not directly addressed by the provided test functions.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_evaluation.py'},\n",
       "   {'ID': '3.2',\n",
       "    'Title': 'Data in the Expected Format',\n",
       "    'Requirement': 'Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.',\n",
       "    'Observation': 'The test functions generate synthetic data in a format suitable for the model evaluation functions. The data is structured as sparse matrices and arrays, which align with the expected format for the algorithms used in the tests.',\n",
       "    'Functions': ['_generate_data'],\n",
       "    'Evaluation': 'Partially Satisfied',\n",
       "    'Score': 0.5,\n",
       "    'file': '../../../lightfm/tests/test_evaluation.py'}],\n",
       "  'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='\\n            Your task is to answer each question in the checklist using only the provided test functions.\\n            If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\\n            Output a JSON format:\\n                {\\n                    \"ID\": \\n                    \"Title\":\\n                    \"Requirement\":\\n                    \"Observation\":\\n                    \"Functions\": [ ... ]\\n                    \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\\n                    \"Score\": (1 for Satisfied / 0.5 for Partially Satisfied / 0 for Not Satisfied)\\n                }\\n        '), AIMessage(content='```json\\n[\\n    {\\n        \"ID\": \"2.1\",\\n        \"Title\": \"Ensure Data File Loads as Expected\",\\n        \"Requirement\": \"Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\",\\n        \"Observation\": \"The test functions do not directly load data files. Instead, they generate synthetic data for testing the model. Therefore, this requirement is not directly covered by the provided test functions.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"2.2\",\\n        \"Title\": \"Ensure Saving Data/Figures Function Works as Expected\",\\n        \"Requirement\": \"Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\",\\n        \"Observation\": \"The test functions do not involve saving data or figures. Therefore, this requirement is not covered by the provided test functions.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.1\",\\n        \"Title\": \"Files Contain Data\",\\n        \"Requirement\": \"Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\",\\n        \"Observation\": \"The test functions do not involve reading data from files. Instead, they generate synthetic data for testing. Therefore, this requirement is not directly addressed by the provided test functions.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.2\",\\n        \"Title\": \"Data in the Expected Format\",\\n        \"Requirement\": \"Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\",\\n        \"Observation\": \"The test functions generate synthetic data in a format suitable for the model evaluation functions. The data is structured as sparse matrices and arrays, which align with the expected format for the algorithms used in the tests.\",\\n        \"Functions\": [\"_generate_data\"],\\n        \"Evaluation\": \"Partially Satisfied\",\\n        \"Score\": 0.5\\n    }\\n]\\n```')])},\n",
       " {'file': '../../../lightfm/tests/test_data.py',\n",
       "  'report': [{'ID': '2.1',\n",
       "    'Title': 'Ensure Data File Loads as Expected',\n",
       "    'Requirement': 'Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.',\n",
       "    'Observation': 'The test functions do not directly involve loading data from files. They focus on testing the fitting and building features functionalities of the Dataset class.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_data.py'},\n",
       "   {'ID': '2.2',\n",
       "    'Title': 'Ensure Saving Data/Figures Function Works as Expected',\n",
       "    'Requirement': 'Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.',\n",
       "    'Observation': 'The test functions do not involve saving data or figures. They focus on testing the fitting, building interactions, and building features functionalities of the Dataset class.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_data.py'},\n",
       "   {'ID': '3.1',\n",
       "    'Title': 'Files Contain Data',\n",
       "    'Requirement': 'Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.',\n",
       "    'Observation': 'The test functions do not involve reading data from external files. They focus on testing the fitting, building interactions, and building features functionalities of the Dataset class.',\n",
       "    'Functions': [],\n",
       "    'Evaluation': 'Not Satisfied',\n",
       "    'Score': 0,\n",
       "    'file': '../../../lightfm/tests/test_data.py'},\n",
       "   {'ID': '3.2',\n",
       "    'Title': 'Data in the Expected Format',\n",
       "    'Requirement': 'Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.',\n",
       "    'Observation': 'The test functions involve creating and manipulating data within the Dataset class using specified formats. The tests ensure that the data is structured correctly within the Dataset object.',\n",
       "    'Functions': ['test_fitting',\n",
       "     'test_fitting_no_identity',\n",
       "     'test_build_features'],\n",
       "    'Evaluation': 'Partially Satisfied',\n",
       "    'Score': 0.5,\n",
       "    'file': '../../../lightfm/tests/test_data.py'}],\n",
       "  'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='\\n            Your task is to answer each question in the checklist using only the provided test functions.\\n            If an answer to the question is provided, it must be annotated with a citation of the test function(s) in the Observation session.\\n            Output a JSON format:\\n                {\\n                    \"ID\": \\n                    \"Title\":\\n                    \"Requirement\":\\n                    \"Observation\":\\n                    \"Functions\": [ ... ]\\n                    \"Evaluation\": Satisfied/Partially Satisfied/Not Satisfied\\n                    \"Score\": (1 for Satisfied / 0.5 for Partially Satisfied / 0 for Not Satisfied)\\n                }\\n        '), AIMessage(content='```json\\n[\\n    {\\n        \"ID\": \"2.1\",\\n        \"Title\": \"Ensure Data File Loads as Expected\",\\n        \"Requirement\": \"Ensure that data-loading functions correctly load files when they exist and match the expected format, handle non-existent files appropriately, and return the expected results.\",\\n        \"Observation\": \"The test functions do not directly involve loading data from files. They focus on testing the fitting and building features functionalities of the Dataset class.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"2.2\",\\n        \"Title\": \"Ensure Saving Data/Figures Function Works as Expected\",\\n        \"Requirement\": \"Verify that functions for saving data and figures perform write operations correctly, checking that the operation succeeds and the content matches the expected format.\",\\n        \"Observation\": \"The test functions do not involve saving data or figures. They focus on testing the fitting, building interactions, and building features functionalities of the Dataset class.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.1\",\\n        \"Title\": \"Files Contain Data\",\\n        \"Requirement\": \"Ensure all data files are non-empty and contain the necessary data required for further analysis or processing tasks.\",\\n        \"Observation\": \"The test functions do not involve reading data from external files. They focus on testing the fitting, building interactions, and building features functionalities of the Dataset class.\",\\n        \"Functions\": [],\\n        \"Evaluation\": \"Not Satisfied\",\\n        \"Score\": 0\\n    },\\n    {\\n        \"ID\": \"3.2\",\\n        \"Title\": \"Data in the Expected Format\",\\n        \"Requirement\": \"Verify that the data to be ingested matches the format expected by processing algorithms (like pd.DataFrame for CSVs or np.array for images) and adheres to the expected schema.\",\\n        \"Observation\": \"The test functions involve creating and manipulating data within the Dataset class using specified formats. The tests ensure that the data is structured correctly within the Dataset object.\",\\n        \"Functions\": [\\n            \"test_fitting\",\\n            \"test_fitting_no_identity\",\\n            \"test_build_features\"\\n        ],\\n        \"Evaluation\": \"Partially Satisfied\",\\n        \"Score\": 0.5\\n    }\\n]\\n```')])}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "579b6e45-5af0-4115-bb16-0b1a9df53b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    results[i]['report'] = extract_json(results[i]['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4a8e944a-802b-4ee1-beae-438d8178f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[2]['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d66d396d-8665-48a1-bd57-299850165e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th>Test_No</th>\n",
       "      <th>Checklist Evaluation</th>\n",
       "      <th>Completeness Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 3, 'Numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'ID': '2.1', 'Requirement': 'Verify the func...</td>\n",
       "      <td>{'Number of satisfied requirements': 2, 'Numbe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Param_Set_ID  Test_No                               Checklist Evaluation  \\\n",
       "0             0        1  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "1             0        2  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "2             0        3  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "3             0        4  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "4             0        5  [{'ID': '2.1', 'Requirement': 'Verify the func...   \n",
       "\n",
       "                                  Completeness Score  \n",
       "0  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "1  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "2  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "3  {'Number of satisfied requirements': 3, 'Numbe...  \n",
       "4  {'Number of satisfied requirements': 2, 'Numbe...  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = pd.concat([results_df, results_df['report'].apply(pd.Series)], axis=1)\n",
    "results_df = results_df.drop(columns='report')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846cf7e-2783-41e0-a190-a9a5a4952946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ce51c6-0dbf-4fa7-8722-5bef38e0224a",
   "metadata": {},
   "source": [
    "## Result & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc750f68-4fa7-4264-a270-2f3cc0ea667c",
   "metadata": {},
   "source": [
    "The evaluation will be based on 2 metrics calculated from the response:\n",
    "- Completeness Score distribution: The distribution of the `num_test_runs` completeness scores per each set of parameters\n",
    "- Consistency Score: Out of all `checklist` items, the proportion of results remain consistent among `num_test_runs` runs per each set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "22ea8a4d-1f08-4f4d-9c80-4dc56ac16b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_score_df = results_df.drop(columns='Checklist Evaluation')\n",
    "completeness_score_df = pd.concat([completeness_score_df, completeness_score_df['Completeness Score'].apply(pd.Series)], axis=1)\n",
    "completeness_score_df['completeness_score'] = completeness_score_df['Number of satisfied requirements'] / completeness_score_df['Number of requirements']\n",
    "completeness_score_df = completeness_score_df.pivot(index='Test_No', columns='Param_Set_ID', values='completeness_score')\n",
    "# completeness_score_df.reset_index()\n",
    "# completeness_score_df.columns.name = 'completeness_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "69617811-0bde-48d2-8604-5ba692a65df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Test_No</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Test_No          1     2     3     4    5\n",
       "Param_Set_ID                             \n",
       "0             0.75  0.75  0.75  0.75  0.5"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_score_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ccd1a25b-674b-4c77-8b32-88ec6600a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_df = results_df.drop(columns='Completeness Score')\n",
    "consistency_df = consistency_df.explode('Checklist Evaluation')\n",
    "consistency_df = pd.concat([consistency_df, consistency_df['Checklist Evaluation'].apply(pd.Series)], axis=1)\n",
    "consistency_df = consistency_df.pivot(index=['Param_Set_ID', 'ID'], columns=['Test_No'], values=['Evaluation'])['Evaluation']\n",
    "consistency_df['consistency'] = consistency_df.eq(consistency_df.iloc[:, 0], axis=0).all(1)\n",
    "# consistency_df = consistency_df.reset_index().drop(columns=['Param_Set_ID'])\n",
    "consistency_df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "28c90383-e3c8-44a9-83a2-344495be26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Param_Set_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>2.1</th>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Not Satisfied</td>\n",
       "      <td>Not Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Not Satisfied</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1</th>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>Partially Satisfied</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    1                    2  \\\n",
       "Param_Set_ID ID                                              \n",
       "0            2.1            Satisfied            Satisfied   \n",
       "             2.2  Partially Satisfied        Not Satisfied   \n",
       "             3.1            Satisfied            Satisfied   \n",
       "             3.2  Partially Satisfied  Partially Satisfied   \n",
       "\n",
       "                                    3                    4  \\\n",
       "Param_Set_ID ID                                              \n",
       "0            2.1            Satisfied            Satisfied   \n",
       "             2.2        Not Satisfied            Satisfied   \n",
       "             3.1            Satisfied            Satisfied   \n",
       "             3.2  Partially Satisfied  Partially Satisfied   \n",
       "\n",
       "                                    5  consistency  \n",
       "Param_Set_ID ID                                     \n",
       "0            2.1            Satisfied         True  \n",
       "             2.2        Not Satisfied        False  \n",
       "             3.1            Satisfied         True  \n",
       "             3.2  Partially Satisfied         True  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consistency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ca45a592-7490-4f86-8357-0707ef81e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consistency_df = consistency_df.reset_index().rename(columns={\"ID\": \"Checklist_ID\"})\n",
    "# consistency_df = consistency_df.groupby(['Param_Set_ID']).mean('consistency')\n",
    "# consistency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c0b4b-ca68-4d44-9cb7-977e08abadb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test-creation]",
   "language": "python",
   "name": "conda-env-test-creation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
